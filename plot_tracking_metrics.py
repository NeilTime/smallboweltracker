#!/usr/bin/env python3
"""
plot_tracking_metrics_with_stats.py

Generate sideâ€‘byâ€‘side boxâ€‘plots of tracking metrics and traceâ€‘length (steps)
from one **or many** ``metrics_per_key.csv`` files produced by
``guided_tracking_evaluator.py`` and print/save the meanÂ Â±Â standard deviation
so you can copyâ€‘paste them straight into your paper/tables.

NEW IN THIS VERSION (2025â€‘07â€‘03)
--------------------------------
* **Folder mode** â€“ pass ``--runfolder`` that points to a directory containing
  *multiple* runâ€‘version folders. The script walks each runâ€‘version,
  recursively locates the *first* ``metrics_per_key.csv`` and concatenates
  them into a single DataFrame.
* Accepts *absolute* or *relative* ``--runfolder``. If relative, it is resolved
  below ``<root_dir>/results<runname>/``.
* Gracefully skips runâ€‘versions that miss the CSV and warns the user.
* Adds a ``RunVersion`` column so you can facet/filter later if desired.
* Keeps the original singleâ€‘run behaviour when ``--runfolder`` is omitted.
* Fixes the path construction bug ("results" + runname â†’ "results<runname>").

Usage examples
--------------
# 1) Legacy (single runâ€‘version)
python plot_tracking_metrics_with_stats.py \
       --runname official_run2 --runversion 9_2025_06_26_21_56

# 2) *All* runâ€‘versions under a given folder
python plot_tracking_metrics_with_stats.py \
       --runname official_run2 --runfolder good_runs

# 3) Absolute folder anywhere on disk
python plot_tracking_metrics_with_stats.py \
       --runfolder C:/experiments/sweep42

Output (per call)
-----------------
* ``plots/<runlabel>/metrics_<runlabel>.png`` â€“ the plot
* ``plots/<runlabel>/summary_stats_<runlabel>.csv`` â€“ tidy table with Î¼ & Ïƒ

The *runlabel* is the folder name when using ``--runfolder`` or the
runâ€‘version name when analysing a single run.
"""

from __future__ import annotations

import argparse
from pathlib import Path
from typing import Tuple

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  CLI â”€ option parsing
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(
        description=(
            "Plot tracking metrics + steps boxâ€‘plots **and** print summary "
            "stats. Works on a *single* runâ€‘version *or* a folder with many."
        )
    )

    p.add_argument(
        "--root_dir",
        default=r"C:\\Users\\P096347\\MSc Thesis\\abdominal_tracker_original",
        help="Project root containing results<runname>/ â€¦ (default: %(default)s)",
    )
    p.add_argument(
        "--runname",
        default="test_bidirectional",
        help="Name of the run, i.e. the X in results_X (default: %(default)s)",
    )

    p.add_argument(
        "--runfolder",
        default="",
        help=(
            "Optional: folder that holds *many* runâ€‘versions. May be an absolute "
            "path or relative to <root_dir>/results<runname>/. If given, all "
            "CSV files found recursively below are aggregated."
        ),
    )

    p.add_argument(
        "--runversion",
        default="latest",
        help="Single runâ€‘version to analyse (ignored when --runfolder is used).",
    )
    p.add_argument(
        "--csv",
        default="metrics_per_key.csv",
        help="Name of the evaluator CSV (default: %(default)s)",
    )
    p.add_argument(
        "--outdir",
        default=r"C:\\Users\\P096347\\MSc Thesis\\abdominal_tracker_original\\plots",
        help="Directory where PNG & stats CSV are written (default: %(default)s)",
    )
    p.add_argument(
        "--fontsize", type=int, default=13, help="Base font size for plots.",
    )

    return p.parse_args()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Matplotlib / Seaborn globals
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def apply_global_font_settings(base_fs: int) -> None:
    """Set matplotlib/Seaborn global font sizes so everything scales together."""

    plt.rcParams.update(
        {
            "font.size": base_fs,
            "axes.titlesize": base_fs + 2,
            "axes.labelsize": base_fs + 1,
            "legend.fontsize": base_fs - 1,
            "legend.title_fontsize": base_fs,
            "xtick.labelsize": base_fs - 1,
            "ytick.labelsize": base_fs - 1,
        }
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Data loading helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _canonical_results_folder(root_dir: Path, runname: str) -> Path:
    """Return <root_dir>/results<runname> (creates no files)."""
    return root_dir / f"results{runname}"


def collect_csvs(args: argparse.Namespace) -> Tuple[pd.DataFrame, str]:
    """Return concatenated DF and a *runlabel* describing the data on disk."""

    base_results = _canonical_results_folder(Path(args.root_dir), args.runname)

    # â”€â”€â”€ Folder mode â€“ aggregate many runâ€‘versions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if args.runfolder:
        runfolder = Path(args.runfolder)
        if not runfolder.is_absolute():
            runfolder = base_results / runfolder

        if not runfolder.is_dir():
            raise FileNotFoundError(f"âŒ  Folder {runfolder} does not exist")

        dfs: list[pd.DataFrame] = []
        for runversion in sorted(p for p in runfolder.iterdir() if p.is_dir()):
            try:
                csv_path = next(runversion.rglob(args.csv))
            except StopIteration:
                print(f"âš ï¸  {runversion.name}: no {args.csv} â€“ skipped")
                continue

            print(f"â†³  Reading {csv_path.relative_to(base_results.parent)}")
            df = pd.read_csv(csv_path)
            df["RunVersion"] = runversion.name  # keep provenance
            dfs.append(df)

        if not dfs:
            raise RuntimeError("âŒ  No CSVs were found â€“ nothing to plot!")

        return pd.concat(dfs, ignore_index=True), runfolder.name

    # â”€â”€â”€ Single runâ€‘version (legacy) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if args.runversion == "latest":
        runs = [d for d in base_results.iterdir() if d.is_dir() and "_" in d.name]
        if not runs:
            raise RuntimeError(f"âŒ  No runâ€‘versions found under {base_results}")
        latest_run = max(runs, key=lambda d: int(d.name.split("_", 1)[0]))
        args.runversion = latest_run.name

    csv_path = base_results / args.runversion / args.csv
    if not csv_path.exists():
        raise FileNotFoundError(f"âŒ  {csv_path} not found")

    print(f"Reading single run {csv_path.relative_to(base_results.parent)}")
    df = pd.read_csv(csv_path)
    df["RunVersion"] = args.runversion

    return df, args.runversion


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Statistics helper
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def summarise_stats(metrics_long: pd.DataFrame, steps_df: pd.DataFrame) -> pd.DataFrame:
    """Return tidy DataFrame with mean & std for each Metric / Dir (+ steps)."""

    by_metric_dir = (
        metrics_long.groupby(["Metric", "Dir"], sort=False)["Score"].agg(["mean", "std"]).reset_index()
    )

    overall = (
        metrics_long.groupby("Metric", sort=False)["Score"].agg(["mean", "std"]).reset_index().assign(Dir="All")
    )

    steps_stats = (
        steps_df.groupby("Dir", sort=False)["Steps"].agg(["mean", "std"]).reset_index().rename(columns={"Dir": "Metric"})
    )
    steps_stats["Metric"] = steps_stats["Metric"].str.capitalize() + " Steps"
    steps_stats.insert(1, "Dir", "Singleâ€‘dir")

    return pd.concat([by_metric_dir, overall, steps_stats], ignore_index=True, sort=False)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main() -> None:
    args = parse_args()
    apply_global_font_settings(args.fontsize)

    df, runlabel = collect_csvs(args)

    # â”€â”€â”€ choose which metrics go where â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    plot_metrics = ["Precision", "Recall", "F1", "Dice"]
    stats_metrics = plot_metrics + ["MSD"]  # MSD only in stats

    hue_order_metrics = ["Forward", "Reverse", "Reverse vs Forward"]
    hue_order_steps = ["Forward", "Reverse"]

    metrics_long = df.melt(
        id_vars=["Key", "Dir"],
        value_vars=stats_metrics,
        var_name="Metric",
        value_name="Score",
    )

    stats_df = summarise_stats(metrics_long, df[df["Dir"].isin(hue_order_steps)])

    # Optional: keep console / CSV ordered
    all_order = stats_metrics + ["Forward Steps", "Reverse Steps"]
    stats_df["Metric"] = pd.Categorical(stats_df["Metric"], categories=all_order, ordered=True)
    stats_df = stats_df.sort_values(["Metric", "Dir"])

    print("\nðŸ“Š  Mean Â± SD of tracking metrics and steps (Î¼ Â± Ïƒ):")
    for _, row in stats_df.iterrows():
        metric_dir = f" ({row.Dir})" if row.Dir not in {"All", "Singleâ€‘dir"} else ""
        print(f"  â€¢ {row.Metric}{metric_dir}: {row['mean']:.3f} Â± {row['std']:.3f}")

    # â”€â”€â”€ output paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    outdir = Path(args.outdir) / runlabel / args.runname
    outdir.mkdir(parents=True, exist_ok=True)

    stats_csv_path = outdir / f"summary_stats_{runlabel}.csv"
    plot_path = outdir / f"metrics_{runlabel}.png"

    stats_df.to_csv(stats_csv_path, index=False)

    # â”€â”€â”€ figure ----------------------------------------------------------------
    fig, axes = plt.subplots(
        1,
        2,
        figsize=(14, 5),
        gridspec_kw={"width_ratios": [4, 1]},
        constrained_layout=True,
    )

    sns.boxplot(
        ax=axes[0],
        data=metrics_long,
        x="Metric",
        y="Score",
        order=plot_metrics,
        hue="Dir",
        hue_order=hue_order_metrics,
        width=0.55,
        showmeans=True,
        meanprops={"marker": "o", "markerfacecolor": "black", "markeredgecolor": "black", "markersize": 7},
    )
    sns.stripplot(
        ax=axes[0],
        data=metrics_long,
        x="Metric",
        y="Score",
        order=plot_metrics,
        hue="Dir",
        hue_order=hue_order_metrics,
        dodge=True,
        jitter=True,
        linewidth=0,
        alpha=0.35,
        size=3,
        legend=False,
    )

    axes[0].set_ylim(0, 1.0)
    axes[0].set_ylabel("Score")
    axes[0].set_title("Tracking Metrics â€“ Forward, Reverse, Reverse vs Forward", pad=10)

    handles, labels = axes[0].get_legend_handles_labels()
    by_label = dict(zip(labels, handles))
    axes[0].legend(by_label.values(), by_label.keys(), title="Direction", loc="lower right", frameon=True)

    # Steps pane -----------------------------------------------------------
    steps_df = df[df["Dir"].isin(hue_order_steps)]

    sns.boxplot(
        ax=axes[1],
        data=steps_df,
        x="Dir",
        y="Steps",
        order=hue_order_steps,
        width=0.55,
        showmeans=True,
        meanprops={"marker": "o", "markerfacecolor": "black", "markeredgecolor": "black", "markersize": 7},
    )

    axes[1].set_xlabel("Direction")
    axes[1].set_ylabel("Steps")
    axes[1].set_title("Trace Length", pad=10)
    if not steps_df["Steps"].empty:
        axes[1].set_ylim(0, steps_df["Steps"].max() * 1.05)

    if axes[1].legend_ is not None:
        axes[1].legend_.remove()

    fig.savefig(plot_path, dpi=300, bbox_inches="tight")

    print(f"\nâœ…  Saved plot to   {plot_path.resolve()}")
    print(f"âœ…  Saved stats to  {stats_csv_path.resolve()}")


if __name__ == "__main__":
    main()
